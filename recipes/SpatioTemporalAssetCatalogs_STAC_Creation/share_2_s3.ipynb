{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import constants\n",
    "import boto3 # had to downgrade boto3 to 1.35.99\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "#set up logging \n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "debug=logging.debug\n",
    "info=logging.info\n",
    "warning=logging.warning\n",
    "error=logging.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use third party object storage to create an S3 Client\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=constants.AWS_S3_ENDPOINT,\n",
    "    aws_access_key_id=constants.AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=constants.AWS_SECRET_ACCESS_KEY,\n",
    ")\n",
    "\n",
    "bucket = constants.AWS_S3_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(bucket_name: str,\n",
    "            object_name: str):\n",
    " \n",
    "    \"\"\"\n",
    "           \n",
    "    This function takes a bucket name, an object name, and an expiration time (in seconds) and generates a URL download link for the object.\n",
    "\n",
    "    Arguments:\n",
    "        bucket_name: String of name of the bucket\n",
    "        object_name: Name of the object (key) that the URL will be pointed to\n",
    "\n",
    "    Returns:\n",
    "        Link of output (object download) URL\n",
    "        \n",
    "    Raises: \n",
    "        Exceptions raised will display an error message and be logged in the export.log file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if r':443' in constants.AWS_S3_ENDPOINT:\n",
    "            endpoint=constants.AWS_S3_ENDPOINT.split(':')\n",
    "            endpoint=fr\"{endpoint[0]}:{endpoint[1]}\"\n",
    "        else:\n",
    "            endpoint=constants.AWS_S3_ENDPOINT\n",
    "        response=os.path.join(endpoint,bucket_name,object_name)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return response\n",
    "\n",
    "def set_permissions(bucket_name: str,\n",
    "                    object_name: str,\n",
    "                    permissions='public-read'):\n",
    "    \"\"\"\n",
    "    This function takes a bucket name, an object name, and a permissions value (specified below) and sets the object's permissions to the value given.\n",
    "\n",
    "    Arguments:\n",
    "        bucket_name: String of name of the bucket\n",
    "        object_name: Name of the object (key) that the URL will be pointed to\n",
    "        permissions: If not specified, the permissions will default to 'public-read'. Otherwise, permissions can be found below:\n",
    "        'private'|'public-read'|'public-read-write'|'authenticated-read'|'aws-exec-read'|'bucket-owner-read'|'bucket-owner-full-control'\n",
    "\n",
    "    Returns:\n",
    "        Nothing\n",
    "        \n",
    "    Raises: \n",
    "        Exceptions raised will display an error message and be logged in the export.log file \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = s3_client.put_object_acl(ACL=permissions, Bucket=bucket_name, Key=object_name)\n",
    "        print(f'Set permissions on {object_name} success, set to {permissions}')\n",
    "    except Exception as e:\n",
    "        print(f'Error when setting permission: double check permission: {permissions}. Refer to help(set_permissions) for documentation.')\n",
    "        print(e)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer=boto3.s3.transfer.S3Transfer(s3_client)\n",
    "\n",
    "# List to store uploaded file URLs\n",
    "uploaded_files = []\n",
    "\n",
    "# import boto3    \n",
    "# s3 = boto3.resource('s3')\n",
    "# s3object = s3.Object('your-bucket-name', 'your_file.json')\n",
    "\n",
    "# s3object.put(\n",
    "#     Body=(bytes(json.dumps(json_data).encode('UTF-8')))\n",
    "# )\n",
    "def upload_folder(json_folder, s3_folder):\n",
    "    for root, _, files in os.walk(json_folder):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "\n",
    "            if os.path.exists(local_file_path):\n",
    "                print(f\"Uploading {local_file_path} to {bucket}/{s3_key}\")\n",
    "                relative_path = os.path.relpath(local_file_path, json_folder)\n",
    "                s3_key = os.path.join(s3_folder, relative_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "                try:\n",
    "                    # s3_client.upload_file(local_file_path, bucket, s3_key)\n",
    "                    # print(f\"Uploaded: {s3_key}\")\n",
    "                    # print(f\"Uploaded: {s3_key}\")\n",
    "                    transfer.upload_file(local_file_path, bucket, s3_key)\n",
    "                    url=create_url(bucket, s3_key)\n",
    "                    set_permissions(bucket, s3_key) # default is public-read\n",
    "                    print(url)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to upload {file}: {e}\")\n",
    "                    \n",
    "def upload_png(png_folder, s3_folder):\n",
    "    if os.path.exists(png_folder):\n",
    "        print(' folder')\n",
    "    else: \n",
    "        print( 'no folder')\n",
    "    for root, _, files in os.walk(png_folder):\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            \n",
    "            if os.path.exists(local_file_path):\n",
    "                print('file exists')\n",
    "                file_name=file.split('.')[0]\n",
    "                relative_path = os.path.relpath(local_file_path, png_folder)\n",
    "                s3_key = os.path.join(s3_folder,file_name, relative_path).replace(\"\\\\\", \"/\")\n",
    "                print(s3_key)\n",
    "                print(f\"Uploading {local_file_path} to {bucket}/{s3_key}\")\n",
    "\n",
    "                # try:\n",
    "                    # s3_client.upload_file(local_file_path, bucket, s3_key)\n",
    "                    # print(f\"Uploaded: {s3_key}\")\n",
    "                    # print(f\"Uploaded: {s3_key}\")\n",
    "                transfer.upload_file(local_file_path, bucket, s3_key)\n",
    "                url=create_url(bucket, s3_key)\n",
    "                set_permissions(bucket, s3_key) # default is public-read\n",
    "                print(url)\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Failed to upload {file}: {e}\")\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "FOLDER_PATH = r\"\\stac\\output\" # Replace with the path to your local folder\n",
    "json_folder=r\"jsons/\"  \n",
    "png_folder= os.path.join(FOLDER_PATH,\"thumbnails\")\n",
    "S3_BASE_PATH = \"BC_STAC\"  # Folder name in S3\n",
    "\n",
    "# Run upload function\n",
    "# upload_folder(FOLDER_PATH, S3_BASE_PATH)\n",
    "upload_png(png_folder,f\"{S3_BASE_PATH}/DEM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
